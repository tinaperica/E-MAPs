{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Title: Gsp1 EMAP clustering analysis\n",
    "Date: 2019 April 02\n",
    "Author: Chris Mathy\n",
    "Email: {chris.mathy@ucsf.edu, cjmathy@gmail.com}\n",
    "Description: Notebook to implement Clustering functional of\n",
    "    Cluster 3.0 in Python, using the Biopython module\n",
    "    Bio.Cluster\n",
    "\n",
    "http://bonsai.hgc.jp/~mdehoon/software/cluster/software.htm#pycluster\n",
    "http://bonsai.hgc.jp/~mdehoon/software/cluster/cluster.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.55'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Bio\n",
    "Cluster.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Cluster\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import os, sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make SGD_descriptions dataframe\n",
    "library_gene_names = list(pd.read_csv('gsp1_pEMAP_avg_merged_gene_names.txt', sep='\\t').columns)[1:]\n",
    "library_gene_ORFs = list(pd.read_csv('gsp1_pEMAP_avg_merged.txt', sep='\\t').columns)[1:]\n",
    "gene_names_to_ORF = pd.DataFrame({'name': library_gene_names,'ORF': library_gene_ORFs})\n",
    "\n",
    "# remove ' - DAmP' and turn 'ORF - ORF' into 'ORF'\n",
    "gene_names_to_ORF['name'], _ = gene_names_to_ORF['name'].str.split(' - ', 1).str\n",
    "gene_names_to_ORF['ORF'], _ = gene_names_to_ORF['ORF'].str.split(' - ', 1).str\n",
    "\n",
    "# get annotations from SGD, code generated from the following URL:\n",
    "# \"https://yeastmine.yeastgenome.org/yeastmine/results.do?trail=%257Cquery\"\n",
    "\n",
    "from intermine.webservice import Service\n",
    "service = Service(\"https://yeastmine.yeastgenome.org:443/yeastmine/service\")\n",
    "query = service.new_query(\"Gene\")\n",
    "query.add_view(\"secondaryIdentifier\", \"symbol\", \"name\", \"length\", \"sgdAlias\", \"description\")\n",
    "query.add_constraint(\"status\", \"IS NULL\", code = \"D\")\n",
    "query.add_constraint(\"status\", \"=\", \"Active\", code = \"C\")\n",
    "query.add_constraint(\"dataSets.name\", \"=\", \"SGD data set\", code = \"F\")\n",
    "query.add_constraint(\"organism.name\", \"=\", \"Saccharomyces cerevisiae\", code = \"E\")\n",
    "query.set_logic(\"(C or D) and E and F\")\n",
    "\n",
    "SGD_annotations = pd.DataFrame(query.results('dict'))\n",
    "cols = list(SGD_annotations.columns)\n",
    "SGD_annotations.columns = [col.split('.')[1] for col in cols]\n",
    "SGD_annotations = SGD_annotations.drop(['cytoLocation','featAttribute','geneSummary',\n",
    "                       'id','length','primaryIdentifier','qualifier',\n",
    "                       'score','scoreType','status'], axis=1)\n",
    "SGD_to_merge = SGD_annotations[['symbol','secondaryIdentifier','description','name']]\n",
    "SGD_to_merge.columns = ['name', 'ORF', 'description', 'name_meaning']\n",
    "\n",
    "df = pd.merge(gene_names_to_ORF, SGD_to_merge, how='left', on=['name','ORF'])\n",
    "\n",
    "# add in hand-curated descriptions from SGD that weren't in the yeastmine download\n",
    "# note, many unknown gene descriptions were left out\n",
    "df = pd.merge(df, pd.read_csv('missing_descriptions.txt', sep='\\t'), how = 'outer')\n",
    "\n",
    "# drop if description is empty (won't add any information)\n",
    "SGD_descriptions = df.loc[~pd.isnull(df.description)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_and_get_clusters(tree, nclusters, list_of_ids):\n",
    "    \n",
    "    # cut tree to get cluster assignments\n",
    "    assigned_clusters = tree.cut(nclusters)\n",
    "    \n",
    "    # count the number of members in each cluster\n",
    "    _, n_in_cluster = np.unique(assigned_clusters, return_counts=True)\n",
    "    \n",
    "    # count the number of clusters of a given size, return as a dict\n",
    "    n_members, n_clusters_of_that_size = np.unique(n_in_cluster, return_counts=True)\n",
    "    cluster_count_by_size = dict(zip(n_members, n_clusters_of_that_size))\n",
    "    \n",
    "    # make a dict of cluster:list pairs, where the list contains member names\n",
    "    clusters = defaultdict(list)\n",
    "    for i, cluster in enumerate(assigned_clusters):\n",
    "        clusters[cluster].append(list_of_ids[i])\n",
    "        \n",
    "    return dict(clusters), cluster_count_by_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we read in the EMAP as a handle, then read the handle into a record object\n",
    "# our record contains:\n",
    "# -- the emap scores in record.data\n",
    "# -- the mutant names in record.geneid\n",
    "# -- the library gene names in record.expid\n",
    "# -- a \"mask\" matrix showing 0's for missing data in record.mask\n",
    "\n",
    "handle = open('gsp1_pEMAP_avg_merged_gene_names.txt')\n",
    "record = Cluster.read(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster with centered correlation (dist=’c’) and average clustering (method == ’v’)\n",
    "\n",
    "# cluster rows (mutants)\n",
    "mutant_clustered = record.treecluster(transpose=False, method='a', dist='c')\n",
    "\n",
    "# cluster columns (library genes)\n",
    "library_clustered = record.treecluster(transpose=True, method='a', dist='c')\n",
    "\n",
    "# scale each, so that cluster distances are between zero and one,\n",
    "# for ease of viewing in Java TreeView\n",
    "mutant_clustered.scale()\n",
    "library_clustered.scale()\n",
    "\n",
    "record.save('avg_clustering', mutant_clustered, library_clustered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[(v,k) for k,v in cluster_dict.items() if len(v) > 1]\n",
    "#{k:v for k,v in cluster_dict.items() if len(v) > 2}\n",
    "#[k for k,v in cluster_dict.items() if len(v) > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 1180\n",
    "\n",
    "cluster_dict, cluster_count_by_size = cut_and_get_clusters(library_clustered, n_clusters, record.expid)\n",
    "\n",
    "cluster_tuples_by_gene_name = [(v,k) for k,v in cluster_dict.items()]\n",
    "\n",
    "gene_cluster_dict = {}\n",
    "\n",
    "for cl in cluster_tuples_by_gene_name:\n",
    "    for gene in cl[0]:\n",
    "        gene_cluster_dict[gene] = cl[1]\n",
    "\n",
    "cluster_df = pd.DataFrame(gene_cluster_dict.items(), columns=['strain', 'cluster'])\n",
    "cluster_df['name'], _ = cluster_df['strain'].str.split(' - ').str\n",
    "\n",
    "df = pd.merge(SGD_descriptions, cluster_df, how = 'left', on = 'name')\n",
    "\n",
    "if not os.path.exists('{}_clusters'.format(n_clusters)):\n",
    "    os.makedirs('{}_clusters'.format(n_clusters))\n",
    "\n",
    "for cl, cluster in df.groupby('cluster'):\n",
    "    if len(cluster) > 2:\n",
    "        cluster.to_csv('{}_clusters/cluster_{}.csv'.format(n_clusters, cl))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
