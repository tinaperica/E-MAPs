
Use Tidyverse for data manipulation in R, and Python for Cluster3.0 and Java Treeview
file preparation
```{r, include=FALSE}
library(tidyverse)
# reticulate for Python setup, including environment
library(reticulate)
use_python("/Users/cjmathy/miniconda3/bin/python")
use_condaenv('lab')
use_python("/Users/cjmathy/miniconda3/bin/python")
```

```{python}
from Bio import Cluster
# Cluster.__version__
import numpy as np
import pandas as pd
import os, sys, datetime
from biocluster_fns import cluster_dataset, cut_and_get_clusters
from sklearn.metrics import adjusted_rand_score
import matplotlib.pyplot as plt
```

'compute_rand_indexes.py'
1. read in full dataset, subsets, interface, and gap gef ratio DONE
2. cluster each one, keep track of matrices using "assign all cuts" DONE
3. run Rand indexes, make them into vectors
4. plot using matplotlib


```{python}

def cluster_and_assign_all_cuts(file, dist):

    with open(file) as handle:
        record = Cluster.read(handle)
    row_tree = record.treecluster(transpose=False, method='a', dist=dist)
    row_tree.scale() 
    
    # cut tree into n clusters, for 1 <= n <= n_elements
    n_elements = len(record.geneid)
    mat = np.zeros((n_elements, n_elements))

    for i in range(n_elements):
        mat[:, i] = row_tree.cut(i+1) # cut into 1 <= i+1 <= n_elements

    return pd.DataFrame(data = mat,
                        dtype = int,
                        index = record.geneid,
                        columns = range(1, n_elements+1))

# make list of tuples of form (name, file), where name will be used in graphs
datasets = [('full_emap', 'gsp1_emap_for_clustering.txt'),
            ('interface', 'core_deltarASA_by_mutant_for_clustering.txt'), # TODO: this clustering is probably bad bc of the NAs
            ('GAP_GEF_ratio', 'GAP_GEF_ratio_for_clustering.txt')]

# add the emap subsets
fdir = 'clustered_emaps'
files = [fdir + '/' + file for file in os.listdir(fdir) if file[-4:] == '.txt']
names = [file.split('_')[0] for file in os.listdir(fdir) if file[-4:] == '.txt']
datasets += [tup for tup in zip(names, files)]

# compute all possible cluster definitions for all datasets
d = {}
for name, file in datasets:
    if name == 'GAP_GEF_ratio':
        d[name] = cluster_and_assign_all_cuts(file, dist = 'e')
    else:
        d[name] = cluster_and_assign_all_cuts(file, dist = 'c')
```


```{python}
d.keys()
```


```{python}

d1 = d['Peroxins']
d2 = d['interface']
d3 = d['full_emap']

vec = range(1, len(d1)-1)
vec1 = [adjusted_rand_score(d1[i+1], d2[i+1]) for i in range(1, len(d1)-1)]
vec2 = [adjusted_rand_score(d1[i+1], d3[i+1]) for i in range(1, len(d1)-1)]


plt.plot(vec, vec1, 'b')
plt.plot(vec, vec2, 'r')

```


